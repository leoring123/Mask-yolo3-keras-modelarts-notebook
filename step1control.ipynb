{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 2 classes.\n",
      "Load weights logs/000ep027-loss15.191-val_loss12.969.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "Train on 233 samples, val on 25 samples, with batch size 16.\n",
      "Unfreeze all of the layers.\n",
      "Train on 233 samples, val on 25 samples, with batch size 16.\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 33s 2s/step - loss: 26.6581 - val_loss: 9098.6631\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 9s 663ms/step - loss: 23.9904 - val_loss: 65.4531\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 9s 661ms/step - loss: 23.1223 - val_loss: 35.7123\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 9s 659ms/step - loss: 24.2268 - val_loss: 402.0731\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 11s 770ms/step - loss: 21.4865 - val_loss: 132.0131\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 11s 811ms/step - loss: 21.6348 - val_loss: 21.8651\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 11s 773ms/step - loss: 20.8685 - val_loss: 28.7770\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 11s 807ms/step - loss: 20.1073 - val_loss: 20.7180\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 11s 779ms/step - loss: 20.4319 - val_loss: 27.1337\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 11s 785ms/step - loss: 19.4290 - val_loss: 18.2455\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 11s 785ms/step - loss: 20.3514 - val_loss: 23.2021\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 11s 790ms/step - loss: 19.3480 - val_loss: 28.7611\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 11s 812ms/step - loss: 19.9761 - val_loss: 25.6862\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 11s 778ms/step - loss: 20.1396 - val_loss: 29.9670\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 11s 780ms/step - loss: 21.2263 - val_loss: 6027.5391\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 10s 719ms/step - loss: 20.3927 - val_loss: 1420.0356\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 11s 790ms/step - loss: 21.6269 - val_loss: 178.7349\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 11s 816ms/step - loss: 20.3994 - val_loss: 79.1804\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 11s 808ms/step - loss: 20.0736 - val_loss: 59.2392\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 11s 815ms/step - loss: 18.8693 - val_loss: 41.9757\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 11s 817ms/step - loss: 18.1679 - val_loss: 22.7097\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 11s 798ms/step - loss: 18.2541 - val_loss: 19.0452\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 11s 821ms/step - loss: 17.4197 - val_loss: 20.6151\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 12s 822ms/step - loss: 18.1061 - val_loss: 22.5033\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 11s 811ms/step - loss: 18.4998 - val_loss: 17.1304\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 11s 809ms/step - loss: 17.6709 - val_loss: 18.0451\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 11s 797ms/step - loss: 18.1192 - val_loss: 22.9546\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 11s 810ms/step - loss: 17.3526 - val_loss: 19.2021\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 12s 840ms/step - loss: 17.9144 - val_loss: 17.2088\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 11s 803ms/step - loss: 17.8391 - val_loss: 18.8542\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 11s 818ms/step - loss: 17.6757 - val_loss: 22.2087\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 12s 844ms/step - loss: 17.1874 - val_loss: 16.6992\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 12s 829ms/step - loss: 18.0226 - val_loss: 18.0634\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 11s 821ms/step - loss: 17.4757 - val_loss: 20.0151\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 11s 806ms/step - loss: 17.7086 - val_loss: 16.2703\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 11s 818ms/step - loss: 18.2298 - val_loss: 21.3364\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 11s 807ms/step - loss: 17.6577 - val_loss: 17.6490\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 11s 818ms/step - loss: 17.9574 - val_loss: 18.5145\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 11s 818ms/step - loss: 17.2875 - val_loss: 19.6918\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 11s 803ms/step - loss: 17.0968 - val_loss: 16.2301\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 11s 797ms/step - loss: 17.9155 - val_loss: 18.9497\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 11s 797ms/step - loss: 17.3339 - val_loss: 19.0758\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 11s 819ms/step - loss: 18.0765 - val_loss: 17.3875\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 11s 817ms/step - loss: 17.5975 - val_loss: 21.3907\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 11s 820ms/step - loss: 17.7022 - val_loss: 17.3240\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 11s 800ms/step - loss: 17.8728 - val_loss: 17.8102\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 11s 817ms/step - loss: 17.4651 - val_loss: 21.3053\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 11s 812ms/step - loss: 17.8297 - val_loss: 17.4134\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 12s 828ms/step - loss: 17.8077 - val_loss: 19.3891\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 11s 817ms/step - loss: 17.8598 - val_loss: 19.0645\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 12s 823ms/step - loss: 18.0734 - val_loss: 20.1104\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 11s 820ms/step - loss: 17.6263 - val_loss: 16.5075\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 11s 808ms/step - loss: 18.0411 - val_loss: 18.2980\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 11s 799ms/step - loss: 18.0559 - val_loss: 20.6952\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 11s 814ms/step - loss: 17.7488 - val_loss: 14.9700\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 11s 794ms/step - loss: 18.1764 - val_loss: 18.7900\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 11s 792ms/step - loss: 17.6417 - val_loss: 20.4486\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 11s 793ms/step - loss: 17.0613 - val_loss: 20.5586\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 11s 821ms/step - loss: 17.6496 - val_loss: 16.2615\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 12s 828ms/step - loss: 18.1490 - val_loss: 24.6832\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 11s 815ms/step - loss: 17.2705 - val_loss: 16.9867\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 11s 805ms/step - loss: 17.5004 - val_loss: 20.3629\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 11s 818ms/step - loss: 18.6979 - val_loss: 16.3846\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 11s 812ms/step - loss: 17.8038 - val_loss: 19.2302\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 12s 830ms/step - loss: 17.7925 - val_loss: 15.8104\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 11s 806ms/step - loss: 17.5117 - val_loss: 22.5666\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 11s 812ms/step - loss: 18.6068 - val_loss: 16.1514\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 11s 797ms/step - loss: 17.8412 - val_loss: 17.4045\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 11s 792ms/step - loss: 17.5872 - val_loss: 19.3474\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 12s 833ms/step - loss: 18.0784 - val_loss: 20.9785\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 11s 804ms/step - loss: 16.9861 - val_loss: 23.1175\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 11s 799ms/step - loss: 17.7933 - val_loss: 16.0286\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 11s 806ms/step - loss: 18.1937 - val_loss: 19.8837\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 11s 808ms/step - loss: 17.6369 - val_loss: 22.0731\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 11s 807ms/step - loss: 17.3428 - val_loss: 17.9419\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 11s 819ms/step - loss: 17.6482 - val_loss: 21.8662\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 11s 800ms/step - loss: 17.8798 - val_loss: 18.5809\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 11s 816ms/step - loss: 17.6772 - val_loss: 18.4213\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 12s 830ms/step - loss: 17.9388 - val_loss: 15.8284\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 12s 834ms/step - loss: 17.5927 - val_loss: 20.8827\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 12s 828ms/step - loss: 17.4667 - val_loss: 17.9322\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 11s 789ms/step - loss: 18.0474 - val_loss: 18.0902\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 11s 791ms/step - loss: 17.2594 - val_loss: 19.0342\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 11s 793ms/step - loss: 17.7765 - val_loss: 22.4039\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 11s 792ms/step - loss: 17.4485 - val_loss: 18.0657\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "Epoch 00085: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrain the YOLO model for your own dataset.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "\n",
    "def _main():\n",
    "    annotation_path = '2020_train.txt'\n",
    "    log_dir = 'logs/000'\n",
    "    classes_path = 'model_data/voc_classes.txt'\n",
    "    anchors_path = 'model_data/yolo_anchors.txt'\n",
    "    class_names = get_classes(classes_path)\n",
    "    num_classes = len(class_names)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
    "    else:\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "            # freeze_body=2, weights_path='model_data/yolo.h5') # make sure you know what you freeze\n",
    "            freeze_body=2, weights_path='logs/000ep027-loss15.191-val_loss12.969.h5')\n",
    "\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1)\n",
    "\n",
    "    val_split = 0.1\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    # Adam(lr=1e-3)\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = 16\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=0,\n",
    "                initial_epoch=0,\n",
    "                callbacks=[logging, checkpoint])\n",
    "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    # Adam(lr=1e-3)\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 16 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=100,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "    # Further training if needed.\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='logs/000ep027-loss15.191-val_loss12.969.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy('s3://kerasyolo3masks416or/yolo.h5','/home/ma-user/work/000ep012-loss17.479-val_loss16.183.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy('/home/ma-user/work/logs/000ep027-loss15.191-val_loss12.969.h5','s3://kerasyolo3masks416or/000ep027-loss15.191-val_loss12.969.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n",
      "WARNING:root:Retry=9, Wait=0.1, Timestamp=1582886696.5964005\n",
      "WARNING:root:Retry=8, Wait=0.2, Timestamp=1582886731.6968112\n",
      "WARNING:root:Retry=7, Wait=0.4, Timestamp=1582886763.775061\n",
      "WARNING:root:Retry=6, Wait=0.8, Timestamp=1582886791.590492\n",
      "WARNING:root:Retry=5, Wait=1.6, Timestamp=1582886815.1772597\n",
      "WARNING:root:Retry=4, Wait=3.2, Timestamp=1582886876.2975488\n",
      "WARNING:root:Retry=3, Wait=6.4, Timestamp=1582886909.1761732\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy('/home/ma-user/work/','s3://kerasyolo3masks416or/kerasyolo3notebook/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.8",
   "language": "python",
   "name": "tensorflow-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
